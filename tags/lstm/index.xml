<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LSTM on A blog</title><link>https://blog.vfiles.no/tags/lstm/</link><description>Recent content in LSTM on A blog</description><generator>Hugo</generator><language>en</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" target="_blank" rel="noopener"&gt;CC BY-SA 4.0&lt;/a&gt;, except where indicated otherwise</copyright><lastBuildDate>Sat, 19 Feb 2022 12:22:06 +0100</lastBuildDate><atom:link href="https://blog.vfiles.no/tags/lstm/index.xml" rel="self" type="application/rss+xml"/><item><title>LSTM for Human Activity Recognition classification</title><link>https://blog.vfiles.no/posts/lstm-for-har/</link><pubDate>Sat, 19 Feb 2022 12:22:06 +0100</pubDate><guid>https://blog.vfiles.no/posts/lstm-for-har/</guid><description>&lt;p&gt;The approach and results of identifying the most accurate collection of attributes from data acquired by embedded smartphone sensors to detect five different daily activities. In this project, we are using a LSTM feature extraction approach with 784 features to distinguish standing, sitting, walking, walking upstairs and downstairs. This approach is getting an accuracy of 92.4% and F1-score of 92.46% as an average for test, train, and validation from the data set created.&lt;/p&gt;</description></item></channel></rss>