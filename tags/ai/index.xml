<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on A blog</title><link>https://blog.vfiles.no/tags/ai/</link><description>Recent content in AI on A blog</description><generator>Hugo</generator><language>en</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" target="_blank" rel="noopener"&gt;CC BY-SA 4.0&lt;/a&gt;, except where indicated otherwise</copyright><lastBuildDate>Sat, 01 Jun 2024 02:02:51 +0200</lastBuildDate><atom:link href="https://blog.vfiles.no/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Riding the AI Hype Train: Destination or Derailment?</title><link>https://blog.vfiles.no/posts/riding-the-ai-hype-train/</link><pubDate>Sat, 01 Jun 2024 02:02:51 +0200</pubDate><guid>https://blog.vfiles.no/posts/riding-the-ai-hype-train/</guid><description>&lt;p&gt;Artificial intelligence (AI) has swiftly transitioned from a niche technology to a mainstream phenomenon, heralded as the next big revolution in tech. Everywhere you turn, AI is making headlines. From self-driving cars and personalized medicine to intelligent robots and chatbots, the promise of AI seems boundless. Nvidia, the company whose chips power much of the AI revolution, recently reported record profits, sparking investor enthusiasm and further fueling the AI hype. However, as we bask in the glow of AI’s potential, it’s crucial to ask: are we aboard a runaway train heading for a catastrophic derailment?&lt;/p&gt;</description></item><item><title>LSTM for Human Activity Recognition classification</title><link>https://blog.vfiles.no/posts/lstm-for-har/</link><pubDate>Sat, 19 Feb 2022 12:22:06 +0100</pubDate><guid>https://blog.vfiles.no/posts/lstm-for-har/</guid><description>&lt;p&gt;The approach and results of identifying the most accurate collection of attributes from data acquired by embedded smartphone sensors to detect five different daily activities. In this project, we are using a LSTM feature extraction approach with 784 features to distinguish standing, sitting, walking, walking upstairs and downstairs. This approach is getting an accuracy of 92.4% and F1-score of 92.46% as an average for test, train, and validation from the data set created.&lt;/p&gt;</description></item></channel></rss>